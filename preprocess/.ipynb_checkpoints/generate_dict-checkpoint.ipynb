{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mol2vec.features import mol2alt_sentence, MolSentence, DfVec, sentences2vec\n",
    "from mol2vec.helpers import depict_identifier, plot_2D_vectors, IdentifierTable, mol_to_svg\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolStandardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol2alt_sentence(mol, radius):\n",
    "    \"\"\"Same as mol2sentence() expect it only returns the alternating sentence\n",
    "    Calculates ECFP (Morgan fingerprint) and returns identifiers of substructures as 'sentence' (string).\n",
    "    Returns a tuple with 1) a list with sentence for each radius and 2) a sentence with identifiers from all radii\n",
    "    combined.\n",
    "    NOTE: Words are ALWAYS reordered according to atom order in the input mol object.\n",
    "    NOTE: Due to the way how Morgan FPs are generated, number of identifiers at each radius is smaller\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mol : rdkit.Chem.rdchem.Mol\n",
    "    radius : float \n",
    "        Fingerprint radius\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        alternating sentence\n",
    "    combined\n",
    "    \"\"\"\n",
    "    radii = list(range(int(radius) + 1))\n",
    "    info = {}\n",
    "    _ = AllChem.GetMorganFingerprint(mol, radius, bitInfo=info)  # info: dictionary identifier, atom_idx, radius\n",
    "\n",
    "    mol_atoms = [a.GetIdx() for a in mol.GetAtoms()]\n",
    "    \n",
    "#     print(mol_atoms)\n",
    "    dict_atoms = {x: {r: None for r in radii} for x in mol_atoms}\n",
    "\n",
    "    for element in info:\n",
    "        for atom_idx, radius_at in info[element]:\n",
    "            dict_atoms[atom_idx][radius_at] = element  # {atom number: {fp radius: identifier}}\n",
    "\n",
    "    # merge identifiers alternating radius to sentence: atom 0 radius0, atom 0 radius 1, etc.\n",
    "    identifiers_alt = []\n",
    "    for atom in dict_atoms:  # iterate over atoms\n",
    "        for r in radii:  # iterate over radii\n",
    "            identifiers_alt.append(dict_atoms[atom][r])\n",
    "\n",
    "    alternating_sentence = map(str, [x for x in identifiers_alt if x])\n",
    "\n",
    "    return list(alternating_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowedAtomsDict = {\n",
    "    'H' : 1,'h' : 0,\n",
    "    'B' : 5,'b' : 0,\n",
    "    'C' : 6,'c' : 0,\n",
    "    'N' : 7,'n' : 0,\n",
    "    'O' : 8,'o' : 0,\n",
    "    'F' : 9,'f' : 0,\n",
    "    'P' : 15,'p': 0,\n",
    "    'S' : 16,'s': 0,\n",
    "    'Cl': 17,'Br' : 35\n",
    "}\n",
    "\n",
    "word = \"AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZzBrCl\"\n",
    "\n",
    "def isValidCharacter(c):\n",
    "    if c not in word or (c in word and c in \"HhBbCcNnOoFfPpSsClBr\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isValidSmiles(smiles,atom_weight = 600,heavy_atom_count = 50):\n",
    "    '''\n",
    "        1. smiles能够被rdkit包处理\n",
    "        2. smiles只包含特定元素\n",
    "        3. smiles原子权重\n",
    "    '''\n",
    "    t_weight = 0\n",
    "    heavyAtomCount = 0\n",
    "    left = -len(smiles)-1\n",
    "    right = -1\n",
    "    idx = -1\n",
    "    while True:\n",
    "        if idx <= left:\n",
    "            break\n",
    "        c = smiles[idx]\n",
    "        if smiles[idx] == 'r' or smiles[idx] == 'l' :\n",
    "            c = (smiles[idx-1] if idx -1 > right else \"#\") + c\n",
    "            idx = idx - 1\n",
    "        idx = idx - 1\n",
    "        if isValidCharacter(c) == True:\n",
    "            if c in allowedAtomsDict.keys():\n",
    "                t_weight = t_weight + int(allowedAtomsDict[c])\n",
    "                heavyAtomCount = heavyAtomCount + (1 if int(allowedAtomsDict[c]) > 1 else 0)\n",
    "        else:\n",
    "            return False\n",
    "#     print(type(t_weight),ttype(heavy_atom_count))\n",
    "    return  True if t_weight >= 3 and t_weight <= atom_weight and heavyAtomCount <= heavy_atom_count else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfc = MolStandardize.fragment.LargestFragmentChooser()\n",
    "def standardizeAndcanonical(smi):\n",
    "    \n",
    "    # standardize\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    mol2 = lfc.choose(mol)\n",
    "    smi2 = Chem.MolToSmiles(mol2)\n",
    "#     print(smi2)\n",
    "#     # canonical\n",
    "#     can_smi = Chem.MolToSmiles(Chem.MolFromSmiles(smi2))\n",
    "# #     print(can_smi)\n",
    "#     print(can_smi == smi2)\n",
    "    return smi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20\n",
      "31 62\n",
      "40 80\n",
      "25 50\n",
      "18 36\n",
      "36 72\n",
      "24 48\n",
      "30 60\n",
      "20 40\n",
      "23 46\n"
     ]
    }
   ],
   "source": [
    "# smiles = 'C[C@@H](O)[C@H]1C(=O)N2C(C(=O)O)=C(S[C@@H]3CN[C@H](Cc4c(CO)c[n+](C)n4C)C3)[C@H](C)[C@H]12'\n",
    "smiles = ['COC(=O)CCC(=O)CN.Cl', 'C[C@@H](O)[C@H]1C(=O)N2C(C(=O)O)=C(S[C@@H]3CN[C@H](Cc4c(CO)c[n+](C)n4C)C3)[C@H](C)[C@H]12.[Cl-]', 'CC(C)NCCNC(=O)CN(CC(=O)N(C)C1Cc2ccccc2C1)c1cc(Cl)ccc1Oc1ccc(Cl)cc1.Cl', 'Cc1nn(CC(=O)O)c2nc3ccccc3c(NCCCN(C)C)c12.Cl', 'COc1ccc(C(N)CCc2ccc(C)o2)cc1.Cl', 'Cc1c[nH]c2cc(/C=C/C(=O)NC3CCC(CCN4CCc5ccc(C#N)cc5CC4)CC3)ccc12.Cl', 'COc1ccccc1CN(C)CC1CC1c1cc(F)ccc1OC.Cl', 'CC(CCc1ccccc1)NCC(O)CON=C1c2ccccc2-c2ccccc21.Cl',\n",
    " 'COc1ccc2c(c1)CC(NCc1ccccc1)CC2.Cl', 'CNCCCNc1c2ccccc2nc2cccc([N+](=O)[O-])c12.Cl']\n",
    "for smi in smiles:\n",
    "    smi = standardizeAndcanonical(smi)\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    sent_0 = mol2alt_sentence(mol,0)\n",
    "    sent_1 = mol2alt_sentence(mol,1)\n",
    "    # print(sent_0)\n",
    "#     print(sent_1[len(sent_0):])\n",
    "    print(len(sent_0),len(sent_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../dataset/pretrain/pretrain_data.txt\"\n",
    "\n",
    "valid_smiles = []\n",
    "total = 0\n",
    "total2 = 0\n",
    "\n",
    "with open(path,\"r\") as f:\n",
    "    for smi in f.readlines():\n",
    "        if smi[-1] == \"\\n\":\n",
    "            smi = smi[:-1]\n",
    "        smi = standardizeAndcanonical(smi)\n",
    "        if isValidSmiles(smi) == True:\n",
    "            t = Chem.MolFromSmiles(smi)\n",
    "            if t != None: # 能够处理\n",
    "                total2 += 1\n",
    "                sentence_rid_0 = mol2alt_sentence(t,0)\n",
    "                sentence_rid_1 = mol2alt_sentence(t,1)\n",
    "#                 print(sentence[0] == 'none')\n",
    "                if sentence_rid_0[0] != 'None' and 2*len(sentence_rid_0) != len(sentence_rid_1):\n",
    "#                     print(len(sentence_rid_0),len(sentence_rid_1))\n",
    "                    total += 1\n",
    "                    valid_smiles.append(smi)\n",
    "        if total2 % 100000 == 0:\n",
    "            print(total == total2)\n",
    "            print(total2 / 4000000)\n",
    "print(total,total2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "path_train = \"../dataset/pretrain/pretrain_data_train.txt\"\n",
    "path_test = \"../dataset/pretrain/pretrain_data_test.txt\"\n",
    "\n",
    "valid_id = [i for i in range(len(valid_smiles))]\n",
    "random.shuffle(valid_id)\n",
    "\n",
    "with open(path_train,\"w\") as f:\n",
    "    \n",
    "    for i in range(0,int(len(valid_id)*0.8)):\n",
    "        idx = valid_id[i]\n",
    "        f.write(valid_smiles[i]+\"\\n\")\n",
    "\n",
    "with open(path_test,\"w\") as f:\n",
    "    for i in range(int(len(valid_id)*0.8)+1,len(valid_id)):\n",
    "        idx = valid_id[i]\n",
    "        f.write(valid_smiles[i]+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smiles-bert",
   "language": "python",
   "name": "smiles-bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
